{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chansikan/do_not_split_small_sample/blob/main/1)Create_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEKScc4Z3V-U"
      },
      "source": [
        "# Radiomics machine learning study with a small sample size: Single random training-test set split may lead to unreliable results: Creating datasets for analyses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RRXlylJA3V-d"
      },
      "outputs": [],
      "source": [
        "# import necessary modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# run an external python code for DeLong method\n",
        "# Upload a file named 'delong.py' onto the working directory\n",
        "%run \"delong.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwTaLwunC30v",
        "outputId": "d3d09b7e-2309-4db3-ab63-c73ab8c9b67c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1) GBM vs. Metastasis dataset: \n",
            "     No. of samples and No. of features: (167, 558) \n",
            "     Proportions of GBM and Metastasis: 0.65 and 0.35 \n",
            "     \n",
            "2) Undersampled GBM vs. Metastasis dataset: \n",
            "     No. of samples and No. of features: (83, 558) \n",
            "     Proportions of GBM and Metastasis: 0.65 and 0.35 \n",
            "     \n",
            "3) Low- vs. High-grade meningioma dataset: \n",
            "     No. of samples and No. of features: (258, 186) \n",
            "     Proportions of Low-grade and High-grade: 0.63 and 0.37 \n",
            "     \n",
            "4) Undersampled Low- vs. High-grade meningioma dataset: \n",
            "     No. of samples and No. of features: (129, 186) \n",
            "     Proportions of Low-grade and High-grade: 0.63 and 0.37 \n",
            "     \n"
          ]
        }
      ],
      "source": [
        "# Upload 4 files onto the working directory:\n",
        "# 'GvM_cohort.csv'\n",
        "# 'GvM_cohort_undersampled.csv'\n",
        "# 'MEN_cohort.csv'\n",
        "# 'MEN_cohort_undersampled.csv'\n",
        "\n",
        "# 1) GBM vs. Metastasis without undersampling\n",
        "df_GvM = pd.read_csv('GvM_cohort.csv')\n",
        "X_GvM = df_GvM.iloc[:, 1:]\n",
        "y_GvM = df_GvM['Label']\n",
        "\n",
        "print('1) GBM vs. Metastasis dataset: \\n \\\n",
        "    No. of samples and No. of features: {0} \\n \\\n",
        "    Proportions of GBM and Metastasis: {1} and {2} \\n \\\n",
        "    '.format(X_GvM.shape, round((1 - np.mean(y_GvM)), 2), \n",
        "             round(np.mean(y_GvM), 2)))\n",
        "\n",
        "# 2) GBM vs. Metastasis with undersampling\n",
        "df_GvM_under = pd.read_csv('GvM_cohort_undersampled.csv')\n",
        "X_GvM_under = df_GvM_under.iloc[:, 1:]\n",
        "y_GvM_under = df_GvM_under['Label']\n",
        "\n",
        "print('2) Undersampled GBM vs. Metastasis dataset: \\n \\\n",
        "    No. of samples and No. of features: {0} \\n \\\n",
        "    Proportions of GBM and Metastasis: {1} and {2} \\n \\\n",
        "    '.format(X_GvM_under.shape, round((1 - np.mean(y_GvM_under)), 2), \n",
        "             round(np.mean(y_GvM_under), 2)))\n",
        "\n",
        "# 3) Low- vs. High-grade meningioma without undersampling\n",
        "df_MEN = pd.read_csv('MEN_cohort.csv')\n",
        "X_MEN = df_MEN.iloc[:, 1:]\n",
        "y_MEN = df_MEN['Label']\n",
        "\n",
        "print('3) Low- vs. High-grade meningioma dataset: \\n \\\n",
        "    No. of samples and No. of features: {0} \\n \\\n",
        "    Proportions of Low-grade and High-grade: {1} and {2} \\n \\\n",
        "    '.format(X_MEN.shape, round((1 - np.mean(y_MEN)), 2), \n",
        "             round(np.mean(y_MEN), 2)))\n",
        "\n",
        "# 4) Low- vs. High-grade meningioma with undersampling\n",
        "df_MEN_under = pd.read_csv('MEN_cohort_undersampled.csv')\n",
        "X_MEN_under = df_MEN_under.iloc[:, 1:]\n",
        "y_MEN_under = df_MEN_under['Label']\n",
        "\n",
        "print('4) Undersampled Low- vs. High-grade meningioma dataset: \\n \\\n",
        "    No. of samples and No. of features: {0} \\n \\\n",
        "    Proportions of Low-grade and High-grade: {1} and {2} \\n \\\n",
        "    '.format(X_MEN_under.shape, round((1 - np.mean(y_MEN_under)), 2), \n",
        "             round(np.mean(y_MEN_under), 2)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V-1NVQxyzjX"
      },
      "source": [
        "## 1) Model stability by No. of input variables, task difficulty, and No. of samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3iD3dEOnVHUZ"
      },
      "outputs": [],
      "source": [
        "def get_auc_by_nfeat(file_data, cv, combs):\n",
        "\n",
        "  df = pd.read_csv(file_data)\n",
        "  X = df.iloc[:, 1:]\n",
        "  y = df.loc[:, 'Label']\n",
        "    \n",
        "  result_df = pd.DataFrame()\n",
        "  for (rs, n_feat) in tqdm(combs):\n",
        "    # splitting\n",
        "    X_train, X_test, y_train, y_test = \\\n",
        "      train_test_split(X, y, test_size=0.3, stratify=y, shuffle=True, random_state=rs)\n",
        "\n",
        "    # standardization\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train, y_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # feature selection\n",
        "    selector = SelectKBest(f_classif, k=n_feat)\n",
        "    X_train = selector.fit_transform(X_train, y_train)\n",
        "    X_test = selector.transform(X_test)\n",
        "\n",
        "    # cross-validated AUC in the training set\n",
        "    clf =  LogisticRegression(penalty='l1', solver='liblinear', max_iter=10000, \n",
        "                              dual=False, random_state=0)\n",
        "    CV_score = cross_val_score(clf, X_train, y_train, scoring='roc_auc', cv=cv)\n",
        "    CV_mean = np.mean(CV_score)\n",
        "    CV_sd = np.std(CV_score)\n",
        "\n",
        "    # model fitting and testing in the training and test sets, respectively\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict_proba(X_test)\n",
        "    test_auc = roc_auc_score(y_test, y_pred[:, 1])\n",
        "\n",
        "    row = pd.DataFrame({'Random_state': rs,\n",
        "                        'Num_features': n_feat,\n",
        "                        'CV_AUC': round(CV_mean, 3), \n",
        "                        'CV_AUC_SD': round(CV_sd, 3),\n",
        "                        'Test_AUC': round(test_auc, 3)}, index = [rs])\n",
        "    result_df = pd.concat([result_df, row], axis=0)\n",
        "  \n",
        "  return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uWRuNzDyXlUl"
      },
      "outputs": [],
      "source": [
        "combs = [(rs, n_feat) \n",
        "         for rs in range(1000) \n",
        "         for n_feat in range(1, 151)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OOD_P1wmUijH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150000/150000 [48:45<00:00, 51.28it/s]\n"
          ]
        }
      ],
      "source": [
        "get_auc_by_nfeat('GvM_cohort.csv', \n",
        "                 cv=5, combs=combs).to_csv('GvM_full_by_nfeat.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DW7QKw_KTaHS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150000/150000 [44:08<00:00, 56.64it/s]\n"
          ]
        }
      ],
      "source": [
        "get_auc_by_nfeat('GvM_cohort_undersampled.csv', \n",
        "                 cv=5, combs=combs).to_csv('GvM_under_by_nfeat.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FMWH7z7fUdW2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150000/150000 [47:54<00:00, 52.17it/s] \n"
          ]
        }
      ],
      "source": [
        "get_auc_by_nfeat('MEN_cohort.csv', \n",
        "                 cv=5, combs=combs).to_csv('MEN_full_by_nfeat.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b4RfRiUlUeSv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150000/150000 [39:57<00:00, 62.58it/s]\n"
          ]
        }
      ],
      "source": [
        "get_auc_by_nfeat('MEN_cohort_undersampled.csv', \n",
        "                 cv=5, combs=combs).to_csv('MEN_under_by_nfeat.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2jyhSs-UmiW"
      },
      "source": [
        "## 2) Model stability with hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "stWGgYTr-ZAM"
      },
      "outputs": [],
      "source": [
        "def get_auc_gridsearch(file_data, rep, cv, params):\n",
        "\n",
        "  df = pd.read_csv(file_data)\n",
        "  X = df.iloc[:, 1:]\n",
        "  y = df.loc[:, 'Label']\n",
        "\n",
        "  result_df = pd.DataFrame()\n",
        "  for rs in tqdm(range(rep)):\n",
        "    X_train, X_test, y_train, y_test = \\\n",
        "          train_test_split(X, y, test_size=0.3, stratify=y, \n",
        "                          shuffle=True, random_state=rs)\n",
        "\n",
        "    pipe = Pipeline([('scaler', StandardScaler()), \n",
        "                    ('fs', SelectKBest(f_classif)),\n",
        "                    ('clf', LogisticRegression(penalty='l1', solver='liblinear',\n",
        "                            max_iter=10000, dual=False, random_state=0))])\n",
        "\n",
        "    search = GridSearchCV(pipe, param_grid=params, scoring='roc_auc', cv=cv)\n",
        "    search.fit(X_train, y_train)\n",
        "\n",
        "    best_nfeat = search.best_params_['fs__k']\n",
        "    best_C = search.best_params_['clf__C']\n",
        "    \n",
        "    auc_list = []\n",
        "    for j in range(cv): \n",
        "        key = 'split'+ str(j) + '_test_score'\n",
        "        auc = search.cv_results_[key][search.best_index_]\n",
        "        auc_list.append(auc)\n",
        "\n",
        "    CV_AUC = np.mean(auc_list)\n",
        "    CV_AUC_SD = np.std(auc_list)\n",
        "\n",
        "    y_pred = search.predict_proba(X_test)\n",
        "    Test_AUC = roc_auc_score(y_test, y_pred[:, 1]) \n",
        "\n",
        "    auc, auc_cov = delong_roc_variance(y_test, y_pred[:, 1])\n",
        "    auc_std = np.sqrt(auc_cov)\n",
        "    lower_upper_q = np.abs(np.array([0, 1]) - (1 - 0.95) / 2)\n",
        "    ci = stats.norm.ppf(lower_upper_q, loc=auc, scale=auc_std)\n",
        "    ci[ci > 1] = 1\n",
        "\n",
        "    row = pd.DataFrame({'Random_state': rs,\n",
        "                        'Optimal_Nfeat': best_nfeat,\n",
        "                        'Optimal_C': best_C,\n",
        "                        'CV_AUC': CV_AUC, 'CV_AUC_SD': CV_AUC_SD,\n",
        "                        'Test_AUC': Test_AUC,\n",
        "                        'CV_AUC_lowCI': ci[0], \n",
        "                        'CV_AUC_highCI': ci[1]}, index = [0])\n",
        "\n",
        "    result_df = pd.concat([result_df, row], axis=0)\n",
        "\n",
        "  return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "26svzjRq_ztt"
      },
      "outputs": [],
      "source": [
        "# define a hyperparameter grid for the ML model\n",
        "C_list = list(np.arange(0.01, 0.1, 0.02)) + \\\n",
        "         list(np.arange(0.1, 1, 0.2)) + \\\n",
        "         list(np.arange(1, 2, 0.5)) + \\\n",
        "         list(np.arange(2, 10, 2))\n",
        "params = {'fs__k': range(20, 55, 5), 'clf__C': C_list}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tGTsEZt6uqHQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1000 [00:05<?, ?it/s]\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_auc_gridsearch(\u001b[39m'\u001b[39;49m\u001b[39mGvM_cohort.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m      2\u001b[0m  rep\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, params\u001b[39m=\u001b[39;49mparams)\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mGvM_full_search.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[9], line 36\u001b[0m, in \u001b[0;36mget_auc_gridsearch\u001b[1;34m(file_data, rep, cv, params)\u001b[0m\n\u001b[0;32m     33\u001b[0m y_pred \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39mpredict_proba(X_test)\n\u001b[0;32m     34\u001b[0m Test_AUC \u001b[39m=\u001b[39m roc_auc_score(y_test, y_pred[:, \u001b[39m1\u001b[39m]) \n\u001b[1;32m---> 36\u001b[0m auc, auc_cov \u001b[39m=\u001b[39m delong_roc_variance(y_test, y_pred[:, \u001b[39m1\u001b[39;49m])\n\u001b[0;32m     37\u001b[0m auc_std \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(auc_cov)\n\u001b[0;32m     38\u001b[0m lower_upper_q \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]) \u001b[39m-\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39m0.95\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n",
            "File \u001b[1;32m~\\Documents\\GitHub\\do_not_split_small_sample\\delong.py:191\u001b[0m, in \u001b[0;36mdelong_roc_variance\u001b[1;34m(ground_truth, predictions, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m order, label_1_count, ordered_sample_weight \u001b[39m=\u001b[39m compute_ground_truth_statistics(\n\u001b[0;32m    189\u001b[0m     ground_truth, sample_weight)\n\u001b[0;32m    190\u001b[0m predictions_sorted_transposed \u001b[39m=\u001b[39m predictions[np\u001b[39m.\u001b[39mnewaxis, order]\n\u001b[1;32m--> 191\u001b[0m aucs, delongcov \u001b[39m=\u001b[39m fastDeLong(predictions_sorted_transposed, label_1_count, ordered_sample_weight)\n\u001b[0;32m    192\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(aucs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mThere is a bug in the code, please forward this to the developers\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m aucs[\u001b[39m0\u001b[39m], delongcov\n",
            "File \u001b[1;32m~\\Documents\\GitHub\\do_not_split_small_sample\\delong.py:56\u001b[0m, in \u001b[0;36mfastDeLong\u001b[1;34m(predictions_sorted_transposed, label_1_count, sample_weight)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfastDeLong\u001b[39m(predictions_sorted_transposed, label_1_count, sample_weight):\n\u001b[0;32m     55\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m         \u001b[39mreturn\u001b[39;00m fastDeLong_no_weights(predictions_sorted_transposed, label_1_count)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m         \u001b[39mreturn\u001b[39;00m fastDeLong_weights(predictions_sorted_transposed, label_1_count, sample_weight)\n",
            "File \u001b[1;32m~\\Documents\\GitHub\\do_not_split_small_sample\\delong.py:140\u001b[0m, in \u001b[0;36mfastDeLong_no_weights\u001b[1;34m(predictions_sorted_transposed, label_1_count)\u001b[0m\n\u001b[0;32m    137\u001b[0m negative_examples \u001b[39m=\u001b[39m predictions_sorted_transposed[:, m:]\n\u001b[0;32m    138\u001b[0m k \u001b[39m=\u001b[39m predictions_sorted_transposed\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 140\u001b[0m tx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty([k, m], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mfloat)\n\u001b[0;32m    141\u001b[0m ty \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty([k, n], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m    142\u001b[0m tz \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty([k, m \u001b[39m+\u001b[39m n], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat)\n",
            "File \u001b[1;32mc:\\Users\\Tom\\.conda\\envs\\py310\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
          ]
        }
      ],
      "source": [
        "get_auc_gridsearch('GvM_cohort.csv', \n",
        " rep=1000, cv=5, params=params).to_csv('GvM_full_search.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_wI5C2q-L36"
      },
      "outputs": [],
      "source": [
        "get_auc_gridsearch('GvM_cohort_undersampled.csv', \n",
        " rep=1000, cv=5, params=params).to_csv('GvM_under_search.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdDIWtEpFdvD"
      },
      "outputs": [],
      "source": [
        "get_auc_gridsearch('MEN_cohort.csv', \n",
        " rep=1000, cv=5, params=params).to_csv('MEN_full_search.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BxJtc6kFd48"
      },
      "outputs": [],
      "source": [
        "get_auc_gridsearch('MEN_cohort_undersampled.csv', \n",
        " rep=1000, cv=5, params=params).to_csv('MEN_under_search.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "1)Create_datasets",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
